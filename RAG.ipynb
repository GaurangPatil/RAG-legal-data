{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36817568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.10.17-py3-none-any.whl (5.6 kB)\n",
      "Collecting llama-index-agent-openai<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.1.5-py3-none-any.whl (12 kB)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_cli-0.1.8-py3-none-any.whl (25 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.17 (from llama-index)\n",
      "  Downloading llama_index_core-0.10.17-py3-none-any.whl (15.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m47.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:09\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.1.6-py3-none-any.whl (6.0 kB)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.1.3-py3-none-any.whl (6.6 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m60.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.1.7-py3-none-any.whl (9.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl (5.8 kB)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.1.4-py3-none-any.whl (4.1 kB)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.1.8-py3-none-any.whl (34 kB)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.1.3-py3-none-any.whl (2.5 kB)\n",
      "Collecting llama-index-vector-stores-chroma<0.2.0,>=0.1.1 (from llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading llama_index_vector_stores_chroma-0.1.5-py3-none-any.whl (4.7 kB)\n",
      "Collecting PyYAML>=6.0.1 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m59.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting SQLAlchemy[asyncio]>=1.4.49 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading SQLAlchemy-2.0.28-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m80.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading aiohttp-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m103.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m128.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting httpx (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m129.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m126.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting llamaindex-py-client<0.2.0,>=0.1.13 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m83.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m90.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nest-asyncio<2.0.0,>=1.5.8 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m105.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m122.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (1.24.3)\n",
      "Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m231.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (9.4.0)\n",
      "Collecting requests>=2.31.0 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m150.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (8.2.2)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading tiktoken-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m132.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm<5.0.0,>=4.66.1 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m240.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m251.7 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (4.6.3)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m244.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m243.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting bs4<0.0.3,>=0.0.2 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Collecting pymupdf<2.0.0,>=1.23.21 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading PyMuPDF-1.23.26-cp311-none-manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m124.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m190.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m200.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting llama-parse<0.4.0,>=0.3.3 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading llama_parse-0.3.7-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.8.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.14.1)\n",
      "Collecting chromadb<0.5.0,>=0.4.22 (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m84.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting onnxruntime<2.0.0,>=1.17.0 (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading onnxruntime-1.17.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m81.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0mm\n",
      "\u001b[?25hCollecting tokenizers<0.16.0,>=0.15.1 (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m78.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic>=1.10 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.17->llama-index) (2.4.2)\n",
      "Requirement already satisfied: anyio in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.17->llama-index) (3.5.0)\n",
      "Requirement already satisfied: certifi in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.17->llama-index) (2023.5.7)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m178.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m168.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.17->llama-index) (3.4)\n",
      "Requirement already satisfied: sniffio in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.2.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m236.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.17->llama-index) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.17->llama-index) (2022.7.9)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Collecting PyMuPDFb==1.23.22 (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m121.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:08\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.17->llama-index) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.17->llama-index) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.17->llama-index) (0.4.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m220.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.17->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.17->llama-index) (2022.7)\n",
      "Collecting build>=1.0.3 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading build-1.1.1-py3-none-any.whl (19 kB)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m152.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m186.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m262.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m229.0 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m177.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading pulsar_client-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m130.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m290.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl (11 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m265.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m121.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m137.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Collecting importlib-resources (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading importlib_resources-6.1.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.59.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m160.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.9.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m122.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tenacity<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m250.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading orjson-3.9.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m277.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m278.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.17->llama-index) (23.0)\n",
      "Collecting coloredlogs (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m239.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers in /home/gaurang/anaconda3/lib/python3.11/site-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /home/gaurang/anaconda3/lib/python3.11/site-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (4.24.3)\n",
      "Requirement already satisfied: sympy in /home/gaurang/anaconda3/lib/python3.11/site-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.11.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.17->llama-index) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.17->llama-index) (2.10.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub<1.0,>=0.16.4 (from tokenizers<0.16.0,>=0.15.1->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m99.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyproject_hooks (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m86.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.9.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (2.23.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.58.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/gaurang/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.2.2)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (6.0.0)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.7/228.7 kB\u001b[0m \u001b[31m68.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n",
      "Collecting opentelemetry-proto==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m108.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl (14 kB)\n",
      "Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n",
      "Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (67.8.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.5/318.5 kB\u001b[0m \u001b[31m28.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m94.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading watchfiles-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m140.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m214.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m224.0 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m146.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m143.7 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.4.8)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=3a2f1f8d97a2581cdcc67499c995a015973089e3765c173728be3eee369ca7ac\n",
      "  Stored in directory: /home/gaurang/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, mmh3, dirtyjson, websockets, uvloop, typing-extensions, tqdm, tenacity, requests, PyYAML, python-dotenv, pyproject_hooks, pypdf, PyMuPDFb, pulsar-client, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, networkx, nest-asyncio, marshmallow, importlib-resources, humanfriendly, httptools, h11, googleapis-common-protos, fsspec, distro, deprecated, chroma-hnswlib, beautifulsoup4, bcrypt, backoff, asgiref, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, SQLAlchemy, pymupdf, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, nltk, huggingface_hub, httpcore, coloredlogs, build, bs4, aiohttp, tokenizers, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, httpx, dataclasses-json, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, openai, llamaindex-py-client, fastapi, opentelemetry-instrumentation-fastapi, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, chromadb, llama-index-vector-stores-chroma, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-agent-openai, llama-index-program-openai, llama-index-cli, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.6.3\n",
      "    Uninstalling typing_extensions-4.6.3:\n",
      "      Successfully uninstalled typing_extensions-4.6.3\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.2.2\n",
      "    Uninstalling tenacity-8.2.2:\n",
      "      Successfully uninstalled tenacity-8.2.2\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.29.0\n",
      "    Uninstalling requests-2.29.0:\n",
      "      Successfully uninstalled requests-2.29.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 2.8.4\n",
      "    Uninstalling networkx-2.8.4:\n",
      "      Successfully uninstalled networkx-2.8.4\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.5.6\n",
      "    Uninstalling nest-asyncio-1.5.6:\n",
      "      Successfully uninstalled nest-asyncio-1.5.6\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.12.2\n",
      "    Uninstalling beautifulsoup4-4.12.2:\n",
      "      Successfully uninstalled beautifulsoup4-4.12.2\n",
      "  Attempting uninstall: bcrypt\n",
      "    Found existing installation: bcrypt 3.2.0\n",
      "    Uninstalling bcrypt-3.2.0:\n",
      "      Successfully uninstalled bcrypt-3.2.0\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.39\n",
      "    Uninstalling SQLAlchemy-1.4.39:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.39\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.7\n",
      "    Uninstalling nltk-3.7:\n",
      "      Successfully uninstalled nltk-3.7\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.15.1\n",
      "    Uninstalling huggingface-hub-0.15.1:\n",
      "      Successfully uninstalled huggingface-hub-0.15.1\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.3\n",
      "    Uninstalling aiohttp-3.8.3:\n",
      "      Successfully uninstalled aiohttp-3.8.3\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.41 requires requests_mock, which is not installed.\n",
      "spyder 5.4.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.4.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "conda-repo-cli 1.0.41 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires nbformat==5.4.0, but you have nbformat 5.7.0 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires PyYAML==6.0, but you have pyyaml 6.0.1 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires requests==2.28.1, but you have requests 2.31.0 which is incompatible.\n",
      "transformers 4.29.2 requires tokenizers!=0.11.3,<0.14,>=0.11.1, but you have tokenizers 0.15.2 which is incompatible.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2024.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyMuPDFb-1.23.22 PyYAML-6.0.1 SQLAlchemy-2.0.28 aiohttp-3.9.3 asgiref-3.7.2 backoff-2.2.1 bcrypt-4.1.2 beautifulsoup4-4.12.3 bs4-0.0.2 build-1.1.1 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 fastapi-0.110.0 fsspec-2024.2.0 googleapis-common-protos-1.62.0 h11-0.14.0 httpcore-1.0.4 httptools-0.6.1 httpx-0.27.0 huggingface_hub-0.21.4 humanfriendly-10.0 importlib-resources-6.1.2 kubernetes-29.0.0 llama-index-0.10.17 llama-index-agent-openai-0.1.5 llama-index-cli-0.1.8 llama-index-core-0.10.17 llama-index-embeddings-openai-0.1.6 llama-index-indices-managed-llama-cloud-0.1.3 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.7 llama-index-multi-modal-llms-openai-0.1.4 llama-index-program-openai-0.1.4 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.8 llama-index-readers-llama-parse-0.1.3 llama-index-vector-stores-chroma-0.1.5 llama-parse-0.3.7 llamaindex-py-client-0.1.13 marshmallow-3.21.1 mmh3-4.1.0 monotonic-1.6 nest-asyncio-1.6.0 networkx-3.2.1 nltk-3.8.1 onnxruntime-1.17.1 openai-1.13.3 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.23.0 opentelemetry-instrumentation-0.44b0 opentelemetry-instrumentation-asgi-0.44b0 opentelemetry-instrumentation-fastapi-0.44b0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 opentelemetry-util-http-0.44b0 orjson-3.9.15 overrides-7.7.0 posthog-3.5.0 pulsar-client-3.4.0 pymupdf-1.23.26 pypdf-4.1.0 pypika-0.48.9 pyproject_hooks-1.0.0 python-dotenv-1.0.1 requests-2.31.0 starlette-0.36.3 tenacity-8.2.3 tiktoken-0.6.0 tokenizers-0.15.2 tqdm-4.66.2 typing-extensions-4.10.0 typing-inspect-0.9.0 uvicorn-0.27.1 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02962b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/gaurang/anaconda3/lib/python3.11/site-packages (1.13.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai) (2.4.2)\n",
      "Requirement already satisfied: sniffio in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7684b453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-huggingface\n",
      "  Using cached llama_index_embeddings_huggingface-0.1.4-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: huggingface-hub[inference]>=0.19.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (0.21.4)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (0.10.17)\n",
      "Collecting torch<3.0.0,>=2.1.2 (from llama-index-embeddings-huggingface)\n",
      "  Downloading torch-2.2.1-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:04\u001b[0m\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.37.0 (from llama-index-embeddings-huggingface)\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.2.0)\n",
      "Requirement already satisfied: requests in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.0)\n",
      "Requirement already satisfied: aiohttp in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.3)\n",
      "Requirement already satisfied: pydantic<3.0,>1.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.2)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.28)\n",
      "Requirement already satisfied: dataclasses-json in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: httpx in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.24.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.13.3)\n",
      "Requirement already satisfied: pandas in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (9.4.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: sympy in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Collecting triton==2.2.0 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.3.52)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface) (0.15.2)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface)\n",
      "  Downloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.8.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.14.1)\n",
      "Requirement already satisfied: anyio in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: certifi in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.4)\n",
      "Requirement already satisfied: idna in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.4)\n",
      "Requirement already satisfied: sniffio in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: click in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic<3.0,>1.1->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic<3.0,>1.1->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2022.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Installing collected packages: triton, safetensors, nvidia-nccl-cu12, torch, transformers, llama-index-embeddings-huggingface\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.18.1\n",
      "    Uninstalling nvidia-nccl-cu12-2.18.1:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.18.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0\n",
      "    Uninstalling torch-2.1.0:\n",
      "      Successfully uninstalled torch-2.1.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.29.2\n",
      "    Uninstalling transformers-4.29.2:\n",
      "      Successfully uninstalled transformers-4.29.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.16.0 requires torch==2.1.0, but you have torch 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed llama-index-embeddings-huggingface-0.1.4 nvidia-nccl-cu12-2.19.3 safetensors-0.4.2 torch-2.2.1 transformers-4.38.2 triton-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dd0c7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f25a6fca734990bf455b346407235f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40582ad2e5d9459885c841cf4fb400ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d053809450b486882f822035e60eb55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e49716424c84115a47d752c7c08c998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba770265da2847bcb7e8312758fe22f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f149b2f2ec6e46a194a67f3fdd36fd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddf4a4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n",
      "[-0.03518998250365257, -0.020716814324259758, 0.05724312737584114, -0.0622982382774353, 0.02225305698812008]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "embeddings = embed_model.get_text_embedding(\"Hello Workkkkkkkkld!jjjjjjjjjjjj\")\n",
    "print(len(embeddings))\n",
    "print(embeddings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b3ecf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader\n",
    "documents=SimpleDirectoryReader(\"../data/AILA_3_docs\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97b320ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73187a41d2c64242beda959144990e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5db067abc784ed5947a00f917789553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents,show_progress=True,embed_model = embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e46505bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`llama-index-llms-llama-cpp` package not found, please run `pip install llama-index-llms-llama-cpp`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/core/llms/utils.py:67\u001b[0m, in \u001b[0;36mresolve_llm\u001b[0;34m(llm, callback_manager)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllama_cpp\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllama_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     68\u001b[0m         completion_to_prompt,\n\u001b[1;32m     69\u001b[0m         messages_to_prompt,\n\u001b[1;32m     70\u001b[0m     )  \u001b[38;5;66;03m# pants: no-infer-dep\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllama_cpp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LlamaCPP  \u001b[38;5;66;03m# pants: no-infer-dep\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.llms.llama_cpp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m query_engine\u001b[38;5;241m=\u001b[39mindex\u001b[38;5;241m.\u001b[39mas_query_engine(llm\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/core/indices/base.py:389\u001b[0m, in \u001b[0;36mBaseIndex.as_query_engine\u001b[0;34m(self, llm, **kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquery_engine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mretriever_query_engine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    384\u001b[0m     RetrieverQueryEngine,\n\u001b[1;32m    385\u001b[0m )\n\u001b[1;32m    387\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_retriever(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    388\u001b[0m llm \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 389\u001b[0m     resolve_llm(llm, callback_manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_manager)\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m llm\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m llm_from_settings_or_context(Settings, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice_context)\n\u001b[1;32m    392\u001b[0m )\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m RetrieverQueryEngine\u001b[38;5;241m.\u001b[39mfrom_args(\n\u001b[1;32m    395\u001b[0m     retriever,\n\u001b[1;32m    396\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    398\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/core/llms/utils.py:81\u001b[0m, in \u001b[0;36mresolve_llm\u001b[0;34m(llm, callback_manager)\u001b[0m\n\u001b[1;32m     74\u001b[0m         llm \u001b[38;5;241m=\u001b[39m LlamaCPP(\n\u001b[1;32m     75\u001b[0m             model_path\u001b[38;5;241m=\u001b[39mmodel_path,\n\u001b[1;32m     76\u001b[0m             messages_to_prompt\u001b[38;5;241m=\u001b[39mmessages_to_prompt,\n\u001b[1;32m     77\u001b[0m             completion_to_prompt\u001b[38;5;241m=\u001b[39mcompletion_to_prompt,\n\u001b[1;32m     78\u001b[0m             model_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_gpu_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m},\n\u001b[1;32m     79\u001b[0m         )\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     82\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`llama-index-llms-llama-cpp` package not found, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease run `pip install llama-index-llms-llama-cpp`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m         )\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m BaseLanguageModel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(llm, BaseLanguageModel):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# NOTE: if it's a langchain model, wrap it in a LangChainLLM\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: `llama-index-llms-llama-cpp` package not found, please run `pip install llama-index-llms-llama-cpp`"
     ]
    }
   ],
   "source": [
    "query_engine=index.as_query_engine(llm='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5346adc7",
   "metadata": {},
   "source": [
    "## New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b3cea36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-vector-stores-pinecone\n",
      "  Downloading llama_index_vector_stores_pinecone-0.1.4-py3-none-any.whl (6.3 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-vector-stores-pinecone) (0.10.17)\n",
      "Collecting pinecone-client<4.0.0,>=3.0.2 (from llama-index-vector-stores-pinecone)\n",
      "  Downloading pinecone_client-3.1.0-py3-none-any.whl (210 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.0/211.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=6.0.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2024.2.0)\n",
      "Requirement already satisfied: httpx in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.24.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.13.3)\n",
      "Requirement already satisfied: pandas in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (9.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.9.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pinecone-client<4.0.0,>=3.0.2->llama-index-vector-stores-pinecone) (2023.5.7)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pinecone-client<4.0.0,>=3.0.2->llama-index-vector-stores-pinecone) (1.26.16)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.8.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.14.1)\n",
      "Requirement already satisfied: pydantic>=1.10 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2.4.2)\n",
      "Requirement already satisfied: anyio in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.0.4)\n",
      "Requirement already satisfied: idna in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (3.4)\n",
      "Requirement already satisfied: sniffio in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.14.0)\n",
      "Requirement already satisfied: click in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2022.7.9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2022.7)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2.10.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.16.0)\n",
      "Installing collected packages: pinecone-client, llama-index-vector-stores-pinecone\n",
      "Successfully installed llama-index-vector-stores-pinecone-0.1.4 pinecone-client-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-vector-stores-pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2a4e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pinecone\n",
    "from pinecone import Pinecone, PodSpec\n",
    "\n",
    "f = open('config.json')\n",
    " \n",
    "\n",
    "data = json.load(f)\n",
    "api_key = data['api_key']\n",
    "\n",
    "pc = pinecone.Pinecone(\n",
    "        api_key=api_key\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d66cac8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ForbiddenException",
     "evalue": "(403)\nReason: Forbidden\nHTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'X-Cloud-Trace-Context': '36f123b909934c6733f011b7c40e4c81', 'Date': 'Sat, 09 Mar 2024 09:23:14 GMT', 'Server': 'Google Frontend', 'Content-Length': '110', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: {\"error\":{\"code\":\"FORBIDDEN\",\"message\":\"Increase your quota or upgrade to create more indexes.\"},\"status\":403}\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mForbiddenException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pc\u001b[38;5;241m.\u001b[39mcreate_index(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjudgments\u001b[39m\u001b[38;5;124m\"\u001b[39m, dimension\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m384\u001b[39m, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m,spec\u001b[38;5;241m=\u001b[39mPodSpec(environment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-west1-gcp\u001b[39m\u001b[38;5;124m\"\u001b[39m,)\n\u001b[1;32m      3\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pinecone/control/pinecone.py:182\u001b[0m, in \u001b[0;36mPinecone.create_index\u001b[0;34m(self, name, dimension, spec, metric, timeout)\u001b[0m\n\u001b[1;32m    180\u001b[0m     api_instance\u001b[38;5;241m.\u001b[39mcreate_index(create_index_request\u001b[38;5;241m=\u001b[39mCreateIndexRequest(name\u001b[38;5;241m=\u001b[39mname, dimension\u001b[38;5;241m=\u001b[39mdimension, metric\u001b[38;5;241m=\u001b[39mmetric, spec\u001b[38;5;241m=\u001b[39mspec\u001b[38;5;241m.\u001b[39masdict()))\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec, PodSpec):\n\u001b[0;32m--> 182\u001b[0m     api_instance\u001b[38;5;241m.\u001b[39mcreate_index(create_index_request\u001b[38;5;241m=\u001b[39mCreateIndexRequest(name\u001b[38;5;241m=\u001b[39mname, dimension\u001b[38;5;241m=\u001b[39mdimension, metric\u001b[38;5;241m=\u001b[39mmetric, spec\u001b[38;5;241m=\u001b[39mspec\u001b[38;5;241m.\u001b[39masdict()))\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspec must be of type dict, ServerlessSpec, or PodSpec\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pinecone/core/client/api_client.py:772\u001b[0m, in \u001b[0;36mEndpoint.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    762\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" This method is invoked when endpoints are called\u001b[39;00m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    770\u001b[0m \n\u001b[1;32m    771\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pinecone/core/client/api/manage_indexes_api.py:371\u001b[0m, in \u001b[0;36mManageIndexesApi.__init__.<locals>.__create_index\u001b[0;34m(self, create_index_request, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_host_index\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_host_index\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    369\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate_index_request\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    370\u001b[0m     create_index_request\n\u001b[0;32m--> 371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_with_http_info(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pinecone/core/client/api_client.py:834\u001b[0m, in \u001b[0;36mEndpoint.call_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    830\u001b[0m     header_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client\u001b[38;5;241m.\u001b[39mselect_header_content_type(\n\u001b[1;32m    831\u001b[0m         content_type_headers_list)\n\u001b[1;32m    832\u001b[0m     params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m header_list\n\u001b[0;32m--> 834\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client\u001b[38;5;241m.\u001b[39mcall_api(\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mendpoint_path\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_method\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    836\u001b[0m     params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    837\u001b[0m     params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    838\u001b[0m     params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheader\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    839\u001b[0m     body\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    840\u001b[0m     post_params\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mform\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    841\u001b[0m     files\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    842\u001b[0m     response_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse_type\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    843\u001b[0m     auth_settings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauth\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    844\u001b[0m     async_req\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124masync_req\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    845\u001b[0m     _check_type\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_return_type\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    846\u001b[0m     _return_http_data_only\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_return_http_data_only\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    847\u001b[0m     _preload_content\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_preload_content\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    848\u001b[0m     _request_timeout\u001b[38;5;241m=\u001b[39mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_request_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    849\u001b[0m     _host\u001b[38;5;241m=\u001b[39m_host,\n\u001b[1;32m    850\u001b[0m     collection_formats\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcollection_format\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pinecone/core/client/api_client.py:409\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Makes the HTTP request (synchronous) and returns deserialized data.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \n\u001b[1;32m    357\u001b[0m \u001b[38;5;124;03mTo make an async_req request, set the async_req parameter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;124;03m    then the method will return the response directly.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_req:\n\u001b[0;32m--> 409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api(resource_path, method,\n\u001b[1;32m    410\u001b[0m                            path_params, query_params, header_params,\n\u001b[1;32m    411\u001b[0m                            body, post_params, files,\n\u001b[1;32m    412\u001b[0m                            response_type, auth_settings,\n\u001b[1;32m    413\u001b[0m                            _return_http_data_only, collection_formats,\n\u001b[1;32m    414\u001b[0m                            _preload_content, _request_timeout, _host,\n\u001b[1;32m    415\u001b[0m                            _check_type)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mapply_async(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api, (resource_path,\n\u001b[1;32m    418\u001b[0m                                                method, path_params,\n\u001b[1;32m    419\u001b[0m                                                query_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    427\u001b[0m                                                _request_timeout,\n\u001b[1;32m    428\u001b[0m                                                _host, _check_type))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pinecone/core/client/api_client.py:203\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m response_data\n\u001b[1;32m    207\u001b[0m return_data \u001b[38;5;241m=\u001b[39m response_data\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pinecone/core/client/api_client.py:196\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host, _check_type)\u001b[0m\n\u001b[1;32m    192\u001b[0m     url \u001b[38;5;241m=\u001b[39m _host \u001b[38;5;241m+\u001b[39m resource_path\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# perform request and return response\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m    197\u001b[0m         method, url, query_params\u001b[38;5;241m=\u001b[39mquery_params, headers\u001b[38;5;241m=\u001b[39mheader_params,\n\u001b[1;32m    198\u001b[0m         post_params\u001b[38;5;241m=\u001b[39mpost_params, body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    199\u001b[0m         _preload_content\u001b[38;5;241m=\u001b[39m_preload_content,\n\u001b[1;32m    200\u001b[0m         _request_timeout\u001b[38;5;241m=\u001b[39m_request_timeout)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PineconeApiException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m     e\u001b[38;5;241m.\u001b[39mbody \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mbody\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pinecone/core/client/api_client.py:455\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mOPTIONS(url,\n\u001b[1;32m    448\u001b[0m                                     query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m    449\u001b[0m                                     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    452\u001b[0m                                     _request_timeout\u001b[38;5;241m=\u001b[39m_request_timeout,\n\u001b[1;32m    453\u001b[0m                                     body\u001b[38;5;241m=\u001b[39mbody)\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mPOST(url,\n\u001b[1;32m    456\u001b[0m                                  query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m    457\u001b[0m                                  headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    458\u001b[0m                                  post_params\u001b[38;5;241m=\u001b[39mpost_params,\n\u001b[1;32m    459\u001b[0m                                  _preload_content\u001b[38;5;241m=\u001b[39m_preload_content,\n\u001b[1;32m    460\u001b[0m                                  _request_timeout\u001b[38;5;241m=\u001b[39m_request_timeout,\n\u001b[1;32m    461\u001b[0m                                  body\u001b[38;5;241m=\u001b[39mbody)\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mPUT(url,\n\u001b[1;32m    464\u001b[0m                                 query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m    465\u001b[0m                                 headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m                                 _request_timeout\u001b[38;5;241m=\u001b[39m_request_timeout,\n\u001b[1;32m    469\u001b[0m                                 body\u001b[38;5;241m=\u001b[39mbody)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pinecone/core/client/rest.py:302\u001b[0m, in \u001b[0;36mRESTClientObject.POST\u001b[0;34m(self, url, headers, query_params, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mPOST\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, query_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, post_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    301\u001b[0m          body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, _preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, _request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOST\u001b[39m\u001b[38;5;124m\"\u001b[39m, url,\n\u001b[1;32m    303\u001b[0m                         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    304\u001b[0m                         query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m    305\u001b[0m                         post_params\u001b[38;5;241m=\u001b[39mpost_params,\n\u001b[1;32m    306\u001b[0m                         _preload_content\u001b[38;5;241m=\u001b[39m_preload_content,\n\u001b[1;32m    307\u001b[0m                         _request_timeout\u001b[38;5;241m=\u001b[39m_request_timeout,\n\u001b[1;32m    308\u001b[0m                         body\u001b[38;5;241m=\u001b[39mbody)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pinecone/core/client/rest.py:253\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnauthorizedException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ForbiddenException(http_resp\u001b[38;5;241m=\u001b[39mr)\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFoundException(http_resp\u001b[38;5;241m=\u001b[39mr)\n",
      "\u001b[0;31mForbiddenException\u001b[0m: (403)\nReason: Forbidden\nHTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'X-Cloud-Trace-Context': '36f123b909934c6733f011b7c40e4c81', 'Date': 'Sat, 09 Mar 2024 09:23:14 GMT', 'Server': 'Google Frontend', 'Content-Length': '110', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\nHTTP response body: {\"error\":{\"code\":\"FORBIDDEN\",\"message\":\"Increase your quota or upgrade to create more indexes.\"},\"status\":403}\n"
     ]
    }
   ],
   "source": [
    "pc.create_index(\n",
    "    \"judgments\", dimension=384, metric=\"cosine\",spec=PodSpec(environment=\"us-west1-gcp\",)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56defe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_indexes = pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9b9ac4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': []}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10c2ae2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pinecone\u001b[38;5;241m.\u001b[39minit(api_key\u001b[38;5;241m=\u001b[39mapi_key, environment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mus-west1-gcp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pinecone/deprecation_warnings.py:38\u001b[0m, in \u001b[0;36minit\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m    import os\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124m    from pinecone import Pinecone, ServerlessSpec\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124m        )\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     31\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124minit is no longer a top-level attribute of the pinecone package.\u001b[39m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124mPlease create an instance of the Pinecone class instead.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mexample\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n",
      "\u001b[0;31mAttributeError\u001b[0m: init is no longer a top-level attribute of the pinecone package.\n\nPlease create an instance of the Pinecone class instead.\n\nExample:\n\n    import os\n    from pinecone import Pinecone, ServerlessSpec\n\n    pc = Pinecone(\n        api_key=os.environ.get(\"PINECONE_API_KEY\")\n    )\n\n    # Now do stuff\n    if 'my_index' not in pc.list_indexes().names():\n        pc.create_index(\n            name='my_index', \n            dimension=1536, \n            metric='euclidean',\n            spec=ServerlessSpec(\n                cloud='aws',\n                region='us-west-2'\n            )\n        )\n\n"
     ]
    }
   ],
   "source": [
    "pinecone.init(api_key=api_key, environment=\"us-west1-gcp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f48856d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

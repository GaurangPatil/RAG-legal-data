{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36817568",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.10.17-py3-none-any.whl (5.6 kB)\n",
      "Collecting llama-index-agent-openai<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_agent_openai-0.1.5-py3-none-any.whl (12 kB)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_cli-0.1.8-py3-none-any.whl (25 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.17 (from llama-index)\n",
      "  Downloading llama_index_core-0.10.17-py3-none-any.whl (15.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m47.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:09\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.1.6-py3-none-any.whl (6.0 kB)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.1.3-py3-none-any.whl (6.6 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Downloading llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m60.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting llama-index-llms-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.1.7-py3-none-any.whl (9.3 kB)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl (5.8 kB)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Downloading llama_index_program_openai-0.1.4-py3-none-any.whl (4.1 kB)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.1.8-py3-none-any.whl (34 kB)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.1.3-py3-none-any.whl (2.5 kB)\n",
      "Collecting llama-index-vector-stores-chroma<0.2.0,>=0.1.1 (from llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading llama_index_vector_stores_chroma-0.1.5-py3-none-any.whl (4.7 kB)\n",
      "Collecting PyYAML>=6.0.1 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (757 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m757.7/757.7 kB\u001b[0m \u001b[31m59.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting SQLAlchemy[asyncio]>=1.4.49 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading SQLAlchemy-2.0.28-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m80.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading aiohttp-3.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m103.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m128.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting httpx (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m129.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m126.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting llamaindex-py-client<0.2.0,>=0.1.13 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m83.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m90.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nest-asyncio<2.0.0,>=1.5.8 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m105.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m122.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (1.24.3)\n",
      "Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m231.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (9.4.0)\n",
      "Collecting requests>=2.31.0 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m150.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (8.2.2)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading tiktoken-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m132.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm<5.0.0,>=4.66.1 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m240.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m251.7 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.17->llama-index) (4.6.3)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m244.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m243.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hCollecting bs4<0.0.3,>=0.0.2 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Collecting pymupdf<2.0.0,>=1.23.21 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading PyMuPDF-1.23.26-cp311-none-manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m124.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading pypdf-4.1.0-py3-none-any.whl (286 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.1/286.1 kB\u001b[0m \u001b[31m190.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m200.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting llama-parse<0.4.0,>=0.3.3 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading llama_parse-0.3.7-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.8.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.14.1)\n",
      "Collecting chromadb<0.5.0,>=0.4.22 (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m84.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting onnxruntime<2.0.0,>=1.17.0 (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading onnxruntime-1.17.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m81.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:03\u001b[0mm\n",
      "\u001b[?25hCollecting tokenizers<0.16.0,>=0.15.1 (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m78.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic>=1.10 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.17->llama-index) (2.4.2)\n",
      "Requirement already satisfied: anyio in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.17->llama-index) (3.5.0)\n",
      "Requirement already satisfied: certifi in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.17->llama-index) (2023.5.7)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m178.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m168.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.17->llama-index) (3.4)\n",
      "Requirement already satisfied: sniffio in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.2.0)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m236.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.17->llama-index) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.17->llama-index) (2022.7.9)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Collecting PyMuPDFb==1.23.22 (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m121.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:08\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.17->llama-index) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.17->llama-index) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.17->llama-index) (0.4.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m220.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.17->llama-index) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.17->llama-index) (2022.7)\n",
      "Collecting build>=1.0.3 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading build-1.1.1-py3-none-any.whl (19 kB)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m152.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fastapi>=0.95.2 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m186.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m262.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m229.0 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m177.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading pulsar_client-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m130.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m290.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl (11 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m265.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m121.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m137.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Collecting importlib-resources (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading importlib_resources-6.1.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.59.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m160.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typer>=0.9.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.9.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m122.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tenacity<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.17->llama-index)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading mmh3-4.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m250.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting orjson>=3.9.12 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading orjson-3.9.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m277.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m278.4 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.17->llama-index) (23.0)\n",
      "Collecting coloredlogs (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m239.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers in /home/gaurang/anaconda3/lib/python3.11/site-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /home/gaurang/anaconda3/lib/python3.11/site-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (4.24.3)\n",
      "Requirement already satisfied: sympy in /home/gaurang/anaconda3/lib/python3.11/site-packages (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.11.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.17->llama-index) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.17->llama-index) (2.10.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.17->llama-index) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub<1.0,>=0.16.4 (from tokenizers<0.16.0,>=0.15.1->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m99.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyproject_hooks (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m86.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.9.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (2.23.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.58.0)\n",
      "Requirement already satisfied: requests-oauthlib in /home/gaurang/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.2.2)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (6.0.0)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.7/228.7 kB\u001b[0m \u001b[31m68.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n",
      "Collecting opentelemetry-proto==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m108.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl (14 kB)\n",
      "Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n",
      "Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (67.8.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading httptools-0.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.5/318.5 kB\u001b[0m \u001b[31m28.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading uvloop-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m94.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m\n",
      "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading watchfiles-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m140.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading websockets-12.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.9/130.9 kB\u001b[0m \u001b[31m214.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m224.0 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m146.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m143.7 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (1.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (4.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index) (0.4.8)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=3a2f1f8d97a2581cdcc67499c995a015973089e3765c173728be3eee369ca7ac\n",
      "  Stored in directory: /home/gaurang/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, mmh3, dirtyjson, websockets, uvloop, typing-extensions, tqdm, tenacity, requests, PyYAML, python-dotenv, pyproject_hooks, pypdf, PyMuPDFb, pulsar-client, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, networkx, nest-asyncio, marshmallow, importlib-resources, humanfriendly, httptools, h11, googleapis-common-protos, fsspec, distro, deprecated, chroma-hnswlib, beautifulsoup4, bcrypt, backoff, asgiref, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, SQLAlchemy, pymupdf, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, nltk, huggingface_hub, httpcore, coloredlogs, build, bs4, aiohttp, tokenizers, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, httpx, dataclasses-json, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, openai, llamaindex-py-client, fastapi, opentelemetry-instrumentation-fastapi, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, chromadb, llama-index-vector-stores-chroma, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-agent-openai, llama-index-program-openai, llama-index-cli, llama-index-question-gen-openai, llama-index\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.6.3\n",
      "    Uninstalling typing_extensions-4.6.3:\n",
      "      Successfully uninstalled typing_extensions-4.6.3\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.2.2\n",
      "    Uninstalling tenacity-8.2.2:\n",
      "      Successfully uninstalled tenacity-8.2.2\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.29.0\n",
      "    Uninstalling requests-2.29.0:\n",
      "      Successfully uninstalled requests-2.29.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 2.8.4\n",
      "    Uninstalling networkx-2.8.4:\n",
      "      Successfully uninstalled networkx-2.8.4\n",
      "  Attempting uninstall: nest-asyncio\n",
      "    Found existing installation: nest-asyncio 1.5.6\n",
      "    Uninstalling nest-asyncio-1.5.6:\n",
      "      Successfully uninstalled nest-asyncio-1.5.6\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.12.2\n",
      "    Uninstalling beautifulsoup4-4.12.2:\n",
      "      Successfully uninstalled beautifulsoup4-4.12.2\n",
      "  Attempting uninstall: bcrypt\n",
      "    Found existing installation: bcrypt 3.2.0\n",
      "    Uninstalling bcrypt-3.2.0:\n",
      "      Successfully uninstalled bcrypt-3.2.0\n",
      "  Attempting uninstall: SQLAlchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.39\n",
      "    Uninstalling SQLAlchemy-1.4.39:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.39\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.7\n",
      "    Uninstalling nltk-3.7:\n",
      "      Successfully uninstalled nltk-3.7\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.15.1\n",
      "    Uninstalling huggingface-hub-0.15.1:\n",
      "      Successfully uninstalled huggingface-hub-0.15.1\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.8.3\n",
      "    Uninstalling aiohttp-3.8.3:\n",
      "      Successfully uninstalled aiohttp-3.8.3\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.2\n",
      "    Uninstalling tokenizers-0.13.2:\n",
      "      Successfully uninstalled tokenizers-0.13.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.41 requires requests_mock, which is not installed.\n",
      "spyder 5.4.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.4.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "conda-repo-cli 1.0.41 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires nbformat==5.4.0, but you have nbformat 5.7.0 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires PyYAML==6.0, but you have pyyaml 6.0.1 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires requests==2.28.1, but you have requests 2.31.0 which is incompatible.\n",
      "transformers 4.29.2 requires tokenizers!=0.11.3,<0.14,>=0.11.1, but you have tokenizers 0.15.2 which is incompatible.\n",
      "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2024.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyMuPDFb-1.23.22 PyYAML-6.0.1 SQLAlchemy-2.0.28 aiohttp-3.9.3 asgiref-3.7.2 backoff-2.2.1 bcrypt-4.1.2 beautifulsoup4-4.12.3 bs4-0.0.2 build-1.1.1 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 fastapi-0.110.0 fsspec-2024.2.0 googleapis-common-protos-1.62.0 h11-0.14.0 httpcore-1.0.4 httptools-0.6.1 httpx-0.27.0 huggingface_hub-0.21.4 humanfriendly-10.0 importlib-resources-6.1.2 kubernetes-29.0.0 llama-index-0.10.17 llama-index-agent-openai-0.1.5 llama-index-cli-0.1.8 llama-index-core-0.10.17 llama-index-embeddings-openai-0.1.6 llama-index-indices-managed-llama-cloud-0.1.3 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.7 llama-index-multi-modal-llms-openai-0.1.4 llama-index-program-openai-0.1.4 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.8 llama-index-readers-llama-parse-0.1.3 llama-index-vector-stores-chroma-0.1.5 llama-parse-0.3.7 llamaindex-py-client-0.1.13 marshmallow-3.21.1 mmh3-4.1.0 monotonic-1.6 nest-asyncio-1.6.0 networkx-3.2.1 nltk-3.8.1 onnxruntime-1.17.1 openai-1.13.3 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.23.0 opentelemetry-instrumentation-0.44b0 opentelemetry-instrumentation-asgi-0.44b0 opentelemetry-instrumentation-fastapi-0.44b0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 opentelemetry-util-http-0.44b0 orjson-3.9.15 overrides-7.7.0 posthog-3.5.0 pulsar-client-3.4.0 pymupdf-1.23.26 pypdf-4.1.0 pypika-0.48.9 pyproject_hooks-1.0.0 python-dotenv-1.0.1 requests-2.31.0 starlette-0.36.3 tenacity-8.2.3 tiktoken-0.6.0 tokenizers-0.15.2 tqdm-4.66.2 typing-extensions-4.10.0 typing-inspect-0.9.0 uvicorn-0.27.1 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02962b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/gaurang/anaconda3/lib/python3.11/site-packages (1.13.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai) (2.4.2)\n",
      "Requirement already satisfied: sniffio in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.10.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7684b453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-huggingface\n",
      "  Using cached llama_index_embeddings_huggingface-0.1.4-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: huggingface-hub[inference]>=0.19.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (0.21.4)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-embeddings-huggingface) (0.10.17)\n",
      "Collecting torch<3.0.0,>=2.1.2 (from llama-index-embeddings-huggingface)\n",
      "  Downloading torch-2.2.1-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:04\u001b[0m\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.37.0 (from llama-index-embeddings-huggingface)\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.2.0)\n",
      "Requirement already satisfied: requests in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.0)\n",
      "Requirement already satisfied: aiohttp in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.9.3)\n",
      "Requirement already satisfied: pydantic<3.0,>1.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.4.2)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.28)\n",
      "Requirement already satisfied: dataclasses-json in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.8)\n",
      "Requirement already satisfied: httpx in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.24.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.13.3)\n",
      "Requirement already satisfied: pandas in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (9.4.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.6.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.9.0)\n",
      "Requirement already satisfied: sympy in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (1.11.1)\n",
      "Requirement already satisfied: jinja2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.0.106)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.1.105)\n",
      "Collecting triton==2.2.0 (from torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface)\n",
      "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (12.3.52)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface) (0.15.2)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.37.0->llama-index-embeddings-huggingface)\n",
      "  Downloading safetensors-0.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.8.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.14.1)\n",
      "Requirement already satisfied: anyio in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.5.0)\n",
      "Requirement already satisfied: certifi in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2023.5.7)\n",
      "Requirement already satisfied: httpcore==1.* in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.0.4)\n",
      "Requirement already satisfied: idna in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.4)\n",
      "Requirement already satisfied: sniffio in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.14.0)\n",
      "Requirement already satisfied: click in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic<3.0,>1.1->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic<3.0,>1.1->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.10.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.26.16)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (3.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (2022.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from sympy->torch<3.0.0,>=2.1.2->llama-index-embeddings-huggingface) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-huggingface) (1.16.0)\n",
      "Installing collected packages: triton, safetensors, nvidia-nccl-cu12, torch, transformers, llama-index-embeddings-huggingface\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.18.1\n",
      "    Uninstalling nvidia-nccl-cu12-2.18.1:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.18.1\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0\n",
      "    Uninstalling torch-2.1.0:\n",
      "      Successfully uninstalled torch-2.1.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.29.2\n",
      "    Uninstalling transformers-4.29.2:\n",
      "      Successfully uninstalled transformers-4.29.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.16.0 requires torch==2.1.0, but you have torch 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed llama-index-embeddings-huggingface-0.1.4 nvidia-nccl-cu12-2.19.3 safetensors-0.4.2 torch-2.2.1 transformers-4.38.2 triton-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-embeddings-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dd0c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "# embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf4a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# embeddings = embed_model.get_text_embedding(\"Hello Workkkkkkkkld!jjjjjjjjjjjj\")\n",
    "# print(len(embeddings))\n",
    "# print(embeddings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b3ecf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core import VectorStoreIndex,SimpleDirectoryReader\n",
    "# documents=SimpleDirectoryReader(\"../data/AILA_3_docs\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97b320ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = VectorStoreIndex.from_documents(documents,show_progress=True,embed_model = embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e46505bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_engine=index.as_query_engine(llm='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5346adc7",
   "metadata": {},
   "source": [
    "## New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b3cea36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-vector-stores-pinecone\n",
      "  Downloading llama_index_vector_stores_pinecone-0.1.4-py3-none-any.whl (6.3 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-vector-stores-pinecone) (0.10.17)\n",
      "Collecting pinecone-client<4.0.0,>=3.0.2 (from llama-index-vector-stores-pinecone)\n",
      "  Downloading pinecone_client-3.1.0-py3-none-any.whl (210 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.0/211.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=6.0.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2024.2.0)\n",
      "Requirement already satisfied: httpx in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (3.8.1)\n",
      "Requirement already satisfied: numpy in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.24.3)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.13.3)\n",
      "Requirement already satisfied: pandas in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.5.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (9.4.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.9.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pinecone-client<4.0.0,>=3.0.2->llama-index-vector-stores-pinecone) (2023.5.7)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pinecone-client<4.0.0,>=3.0.2->llama-index-vector-stores-pinecone) (1.26.16)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.8.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.14.1)\n",
      "Requirement already satisfied: pydantic>=1.10 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2.4.2)\n",
      "Requirement already satisfied: anyio in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (3.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.0.4)\n",
      "Requirement already satisfied: idna in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (3.4)\n",
      "Requirement already satisfied: sniffio in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.14.0)\n",
      "Requirement already satisfied: click in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2022.7.9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2.0.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.4.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (3.21.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2022.7)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (2.10.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/gaurang/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-vector-stores-pinecone) (1.16.0)\n",
      "Installing collected packages: pinecone-client, llama-index-vector-stores-pinecone\n",
      "Successfully installed llama-index-vector-stores-pinecone-0.1.4 pinecone-client-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-vector-stores-pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f90e1",
   "metadata": {},
   "source": [
    "- https://docs.pinecone.io/docs/new-api\n",
    "- https://docs.llamaindex.ai/en/stable/examples/low_level/retrieval.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53310b8b",
   "metadata": {},
   "source": [
    "# Retrieve api key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d2a4e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pinecone\n",
    "from pinecone import Pinecone, PodSpec\n",
    "\n",
    "f = open('config.json')\n",
    " \n",
    "\n",
    "data = json.load(f)\n",
    "api_key = data['api_key']\n",
    "\n",
    "pc = pinecone.Pinecone(\n",
    "        api_key=api_key\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691577ba",
   "metadata": {},
   "source": [
    "# Create index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d66cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.create_index(\n",
    "    \"judgments\", dimension=384, metric=\"cosine\",spec=PodSpec(\n",
    "    environment=\"gcp-starter\"\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56defe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_indexes = pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b9ac4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': [{'dimension': 384,\n",
       "              'host': 'judgments-m7a6ou0.svc.gcp-starter.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'judgments',\n",
       "              'spec': {'pod': {'environment': 'gcp-starter',\n",
       "                               'pod_type': 'starter',\n",
       "                               'pods': 1,\n",
       "                               'replicas': 1,\n",
       "                               'shards': 1}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f48856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_index = pinecone.Index(host=\"judgments-m7a6ou0.svc.gcp-starter.pinecone.io\",api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6635cc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2560b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fcaae58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader\n",
    "# experimenting with few docs only\n",
    "documents=SimpleDirectoryReader(\"../data/AILA_3_docs\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "611aba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core import StorageContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a062956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d761853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# embeddings = embed_model.get_text_embedding(\"Hello Workkkkkkkkld!jjjjjjjjjjjj\")\n",
    "# print(len(embeddings))\n",
    "# print(embeddings[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9ffc27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57ed8487",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061a8421222b4669a774b820b50624b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# splitter = SentenceSplitter(chunk_size=1024)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, storage_context=storage_context,embed_model=embed_model\n",
    ")\n",
    "# , transformations=[splitter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c736e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"bullet injury\"\n",
    "query_embedding = embed_model.get_query_embedding(query_str)\n",
    "from llama_index.core.vector_stores import VectorStoreQuery\n",
    "\n",
    "query_mode = \"default\"\n",
    "# query_mode = \"sparse\"\n",
    "# query_mode = \"hybrid\"\n",
    "\n",
    "vector_store_query = VectorStoreQuery(\n",
    "    query_embedding=query_embedding, similarity_top_k=3, mode=query_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "325256d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a VectorStoreQueryResult\n",
    "query_result = vector_store.query(vector_store_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb2e59dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gaurang/DSAC/RAG-legal-data/../data/AILA_3_docs/C6.txt'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_result.nodes[0].metadata['file_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798b28d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a6624c5",
   "metadata": {},
   "source": [
    "# To delete the index (don't run if all docs are already indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8593cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.delete_index('judgments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d7b98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
